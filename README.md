# ğŸ§® Math Tutor CLI - EdTech Assistant

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![LM Studio](https://img.shields.io/badge/LM%20Studio-Compatible-green.svg)](https://lmstudio.ai)

**Domain-Specific LLM Agent for Class 6-10 Mathematics Education**

A sophisticated Math Tutor CLI application that demonstrates advanced prompt engineering strategies using local LLMs via LM Studio. This project implements and evaluates four different prompting approaches for educational AI applications.

## ğŸ“‘ Table of Contents

- [âœ¨ Features](#-features)
- [ğŸš€ Installation & Setup](#-installation--setup)
- [ğŸ¬ Demo](#-demo)
- [ğŸ”§ Core Features](#-core-features)
- [ğŸ’» Usage Examples](#-usage-examples)
- [ğŸ“Š Evaluation Results](#-evaluation-results)
- [ğŸ—ï¸ Repository Structure](#ï¸-repository-structure)
- [ğŸ¯ Assignment Deliverables Mapping](#-assignment-deliverables-mapping)
- [ğŸ”§ Troubleshooting](#-troubleshooting)
- [ğŸ“– Additional Documentation](#-additional-documentation)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“„ License](#-license)

## âœ¨ Features

- ğŸ¯ **Four Prompt Engineering Strategies**: Zero-shot, Few-shot, Chain-of-Thought, and Self-ask
- ğŸ“Š **Comprehensive Evaluation Framework**: Multi-metric scoring system with accuracy, reasoning, hallucination detection, and consistency testing
- ğŸ›¡ï¸ **Intelligent Fallback Mechanism**: Handles ambiguous inputs with clarification prompts
- ğŸ§® **Educational Focus**: Designed specifically for Class 6-10 mathematics curriculum
- ğŸ’» **CLI Interface**: Beautiful, user-friendly command-line interface with colored output
- ğŸ“ˆ **Batch Evaluation**: Automated testing across all strategies and problems
- ğŸ”„ **Interactive Mode**: Conversational interface for continuous problem-solving
- ğŸ“‹ **Detailed Reporting**: CSV exports with timestamps and comprehensive analysis

## ğŸ“‹ Assignment Context

**Domain**: EdTech Math Tutor for Class 6-10 curriculum  
**Technology**: LM Studio + meta-llama-3.1-8b-instruct  
**Focus**: Prompt engineering, evaluation, and comparison of different strategies

### ğŸ¯ Three Representative User Tasks

1. **Step-by-step Problem Solving**: "Solve for x: 2x + 5 = 15"
2. **Concept Explanation**: "Explain how to find the area of a circle"  
3. **Student Work Verification**: "Check if this solution is correct: [student work]"

## ğŸš€ Installation & Setup

### Prerequisites

- Python 3.8 or higher
- macOS, Linux, or Windows
- 8GB+ RAM recommended for local LLM inference

### 1. Clone the Repository

```bash
git clone <your-repository-url>
cd math-tutor-cli
```

### 2. LM Studio Setup
- Download [LM Studio](https://lmstudio.ai) for your operating system
- Install and launch LM Studio
- Download the `meta-llama-3.1-8b-instruct` model (recommended)
- Start the local server on `http://localhost:1234`

### 3. Python Environment Setup
   ```bash
   # Create and activate virtual environment
   python -m venv math_tutor_env
   source math_tutor_env/bin/activate  # On macOS/Linux
   
   # Install Python dependencies
   pip install -r requirements.txt
   ```

### 4. Quick Start

```bash
# Activate virtual environment first
source math_tutor_env/bin/activate

# Test the connection and see examples
python main.py --help-examples

# Solve a single problem
python main.py --problem "Solve: 2x + 5 = 15" --strategy cot

# Run evaluation on all strategies
python main.py --evaluate

# Interactive mode
python main.py --interactive
```

## ğŸ¬ Demo

### Single Problem Solving
```bash
python main.py --problem "Find the area of a circle with radius 5 cm" --strategy cot
```

**Output:**
```
ğŸ” Analyzing Problem...
Problem: Find the area of a circle with radius 5 cm
Strategy: cot

ğŸ¤” Thinking with Chain-of-Thought approach...

âœ… SOLUTION:
============================================================
Let me solve this step by step:

1. First, I need to identify what we're looking for: the area of a circle
2. The formula for the area of a circle is: A = Ï€rÂ²
3. Given information: radius (r) = 5 cm
4. Substituting into the formula: A = Ï€ Ã— (5)Â²
5. Calculating: A = Ï€ Ã— 25 = 25Ï€ cmÂ²
6. Using Ï€ â‰ˆ 3.14159: A â‰ˆ 78.54 cmÂ²

Therefore, the area of the circle is 25Ï€ cmÂ² or approximately 78.54 cmÂ².
============================================================
```

### Batch Evaluation Results
```
ğŸ† STRATEGY RANKINGS (Overall Score)
========================================
1. Chain-of-Thought: 0.847
2. Few-shot: 0.823  
3. Self-ask: 0.791
4. Zero-shot: 0.765
```

## ğŸ”§ Core Features

### ğŸ¯ **4 Prompt Engineering Strategies**

| Strategy | Description | Use Case |
|----------|-------------|----------|
| **Zero-shot** | Direct problem solving without examples | Quick, straightforward problems |
| **Few-shot** | Learning from 2-3 examples before solving | Complex problems needing context |
| **Chain-of-Thought** | Step-by-step reasoning process | Problems requiring detailed explanation |
| **Self-ask** | Agent asks clarifying questions first | Ambiguous or multi-part problems |

### ğŸ“Š **Evaluation Framework**

**Metrics Measured**:
- **Accuracy** (0-1): Correctness of final answer
- **Reasoning Clarity** (1-5): Quality of step-by-step explanation  
- **Hallucination Score** (0-3): Mathematical errors or false statements
- **Consistency** (0-1): Same answer for repeated queries

### ğŸ›¡ï¸ **Fallback Mechanism**

Handles ambiguous inputs like:
- "help with math"
- "solve this problem" 
- "I need help"

Provides clarification prompts to guide users toward specific problems.

## ğŸ“š Test Dataset

**8 Curated Problems** covering Class 6-10 curriculum:

| Problem | Category | Grade | Difficulty |
|---------|----------|-------|------------|
| Linear equations | Algebra | 8-9 | Medium |
| Circle area | Geometry | 7-8 | Medium |
| Percentage calculation | Arithmetic | 6-7 | Easy |
| Quadratic equations | Algebra | 10 | Hard |
| Speed-distance-time | Physics-Math | 7-8 | Easy |
| Trigonometry | Advanced | 10 | Medium |
| Algebraic expressions | Algebra | 8 | Easy |
| Rectangle perimeter | Geometry | 6-7 | Medium |

## ğŸ’» Usage Examples

### Interactive Problem Solving

```bash
# Activate environment first
source math_tutor_env/bin/activate

# Zero-shot approach
python main.py --problem "What is 15% of 240?" --strategy zero-shot

# Few-shot with examples
python main.py --problem "Solve: xÂ² - 5x + 6 = 0" --strategy few-shot

# Chain-of-thought reasoning
python main.py --problem "Find area of circle with radius 7 cm" --strategy cot

# Self-questioning approach
python main.py --problem "A train travels 120 km in 2 hours. What is its speed?" --strategy self-ask
```

### Batch Evaluation

```bash
# Activate environment first
source math_tutor_env/bin/activate

# Test all strategies on all problems (32 total tests)
python main.py --evaluate

# Test only Chain-of-Thought strategy
python main.py --evaluate --strategy cot

# Results saved to results/ directory with timestamps
```

### Interactive Mode

```bash
# Activate environment first
source math_tutor_env/bin/activate

python main.py --interactive
# Provides conversational interface for continuous problem solving
```

## ğŸ“Š Evaluation Results

After running evaluation, you'll get:

1. **Strategy Comparison Report**: Performance metrics for each prompt strategy
2. **Strategy Rankings**: Overall scores with weighted metrics displayed in terminal
3. **Detailed CSV Reports**: Timestamped results in `results/` folder
   - `detailed_results_[timestamp].csv` - Individual test results
   - `strategy_comparison_[timestamp].csv` - Summary comparison

### Sample Output
```
ğŸ† STRATEGY RANKINGS (Overall Score)
========================================
1. Chain-of-Thought: 0.847
2. Few-shot: 0.823  
3. Self-ask: 0.791
4. Zero-shot: 0.765
```

## ğŸ—ï¸ Repository Structure

```
math-tutor-cli/
â”œâ”€â”€ main.py                        # CLI interface & LM Studio integration
â”œâ”€â”€ prompt_strategies.py           # 4 prompt strategies + fallback handler
â”œâ”€â”€ evaluator.py                   # Testing framework & scoring system
â”œâ”€â”€ test_queries.py               # 8 curated test problems dataset
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ README.md                     # Project documentation
â”œâ”€â”€ ASSIGNMENT_METHODOLOGY.md     # Technical methodology & analysis
â”œâ”€â”€ math_tutor_env/              # Virtual environment (created after setup)
â””â”€â”€ results/                     # Generated evaluation reports (created after runs)
    â”œâ”€â”€ detailed_results_[timestamp].csv
    â””â”€â”€ strategy_comparison_[timestamp].csv
```

## ğŸ¯ Assignment Deliverables Mapping

### **Part 1**: Domain Understanding âœ…
- **Domain**: EdTech Math Tutor (Class 6-10)
- **User Tasks**: Problem solving, concept explanation, work verification
- **Implementation**: `test_queries.py` + documentation

### **Part 2**: Prompt Engineering âœ…  
- **4 Strategies**: Zero-shot, Few-shot, CoT, Self-ask in `prompt_strategies.py`
- **Fallback Mechanism**: Ambiguity detection and clarification
- **Automation**: Batch testing framework in `evaluator.py`
- **Hallucination Logging**: Automatic detection and reporting

### **Part 3**: Evaluation & Analysis âœ…
- **Accuracy**: Correct answer matching
- **Reasoning**: Step-by-step clarity scoring  
- **Hallucination**: Mathematical error detection
- **Consistency**: Repeated query testing
- **Comparison**: Strategy performance analysis

## ğŸ”§ Troubleshooting

### Common Issues

1. **LM Studio Connection Failed**:
   ```bash
   # Ensure LM Studio is running with server started
   # Check http://localhost:1234 is accessible
   ```

2. **Model Not Found**:
   ```bash
   # Download meta-llama-3.1-8b-instruct in LM Studio
   # Ensure model is loaded before starting server
   ```

3. **Virtual Environment Issues**:
   ```bash
   # Make sure to activate the virtual environment
   source math_tutor_env/bin/activate
   
   # If modules are missing, reinstall dependencies
   pip install -r requirements.txt
   ```

4. **Memory Issues on M1 Mac**:
   ```bash
   # Use Phi-3-Mini or Mistral-7B if Llama is too large
   # Adjust model in main.py LMStudioClient initialization
   ```

## ğŸ“– Additional Documentation

For comprehensive technical details, methodology, and implementation insights, see:
- **`ASSIGNMENT_METHODOLOGY.md`** - Complete technical documentation explaining:
  - Detailed workflow and architecture
  - In-depth prompt strategy analysis
  - Evaluation methodology and scoring systems
  - Strategy effectiveness analysis
  - Implementation details and rationale

